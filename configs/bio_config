# pretrained embeddings
filename_embeddings     =data/dataset/vecs.lc.over100freq.txt

# dataset
filename_dev            = "data/dataset/dev.txt"
filename_test           = "data/dataset/test.txt"
filename_train          = "data/dataset/train.txt"

# training
nepochs                 = 150
optimizer               = Adam
activation              = tanh
learning_rate           = 1e-3
gradientClipping        = False # if False, no clipping
nepoch_no_imprv         = 30
use_dropout             = True
ner_loss                = crf # or softmax
use_chars               = True 
use_adversarial         = False
ner_classes             = BIO #or EC for entity classification
initializer             = glorot
use_position            = False
use_GRU                 = False
self_attention          = True
use_bias                = True

#hyperparameters
dropout_embedding       = 0.9
dropout_lstm            = 0.9
dropout_lstm_output     = 0.9
dropout_fcl_ner         = 1
dropout_fcl_rel         = 1
gru_keep_prob           = 0.5
hidden_size_lstm        = 64
hidden_size_n1          = 64
#hidden_size_n2          = 32
num_lstm_layers         = 3
char_embeddings_size    = 25
hidden_size_char        = 25
label_embeddings_size   = 5 #if 0, no label embeddings
alpha                   = 0.01
lmcost_lstm_gamma       = 0.1
lmcost_joint_lstm_gamma = 0.0
lmcost_hidden_layer_size = 50
lmcost_max_vocab_size   = 7500
gru_size                = 230
pos_num                 = 123
pos_size                = 5
num_heads               = 8
weight_b                = 9.0

#evaluation
evaluation_method       = strict # alternatives "boundaries" and "relaxed"
root_node               = False 
